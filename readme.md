# Лабораторная работа №3

## Airflow и MLflow - логгирование экспериментов и версионирование моделей

В рамках данной лабораторной работы предлагается построить два пайплайна:

1. Пайплайн, который обучает любой классификатор из sklearn по заданному набору параметров.
2. Пайплайн, который выбирает лучшую модель из обученных и производит её хостинг.

Для построения такого пайплайна воспользуемся следующими инструментами:

- Apache Airflow
- MLflow

## Подготовка к выполнению задания

Для выполнения лабораторной работы рекомендуется использовать докер контейнеры из подготовительного репозитория: https://github.com/ssau-data-engineering/Prerequisites/tree/main

## Задание на лабораторную работу

### Пайплайн для обучения классификаторов

Построенный пайплайн будет выполнять следующие действия поочередно:

1. Производить мониторинг целевой папки на предмет появления новых конфигурационных файлов классификаторов (в форматах `.json` или `.yaml`).
2. Обучать классификатор в соответствии с полученными параметрами. 
   - Производить логгирование параметров модели в **MLflow**. 
   - Производить логгирование процесса обучения **MLflow**. 
   - Производить тестирование модели и сохранять его результаты в **MLflow**.
3. Сохранять обученный классификатор в `model registry` **MLflow**.

### Пайплайн для хостинга лучшей модейли

Построенный пайплайн будет выполнять следующие действия поочередно:

1. В соответствии с таймером производит валидацию новых моделей из `model registry`.
2. Модель с лучшим показателем метрики переводится на `stage: Production`
3. (Опционально) произвести хостинг лучшей модели

## Сдача лабораторной работы

Для успешной сдачи лабораторной работы ваш репозиторий должен содержать следующее:

1. Обучить при помощи пайплайнов не менее пяти классификаторов с различными параметрами
2. Отчет, описывающий этапы выполнения работы (скриншоты, описание встреченных проблем и их решения приветствуются) в формате .pdf или .md.
   - *Отчет также должен содержать скриншоты со страниц как Airflow, так и MLflow*
3. Программный код, реализующий пайплайны.
4. Открыт Pull Request в данный репозиторий.

## FAQ

- В рамках настоящей работы можно обойтись без использование `DockerOperator`
- Все сохраняемые в рамках работы модели - сохраняются в объектное хранилище **Minio** (доступное по адресу: http://localhost:9000 minio@minio123).
Это можно использовать при построении сложных пайплайнов для осуществления обмена данными между различными узлами системы.
- Чтобы Airflow смог сохранить модель - необходимо в файле описывающем **DAG** установить также переменные среды:
    ```python
    import os

    os.environ["AWS_ACCESS_KEY_ID"] = "minio"
    os.environ["AWS_SECRET_ACCESS_KEY"] = "minio123"
    os.environ["MLFLOW_S3_ENDPOINT_URL"] = "http://minio:9000"
    ```
- Пример файла конфигурации классификатора:
    ```yaml
    classificator: sklearn.neural_network.MLPClassifier
    kwargs:
    - hidden_layer_sizes:
        - 20
        - 100
        - 20
    - activation: relu
    - solver: adam
    - learning_rage: 0.001
    ```
- При выполнении работы настоятельно рекомендуется пользоваться официальной докумментацией:
  * https://mlflow.org/docs/latest/model-registry.html#mlflow-model-registry
  * https://mlflow.org/docs/latest/tracking.html#logging-data-to-runs
  * https://mlflow.org/docs/latest/models.html
  * https://mlflow.org/docs/latest/search-runs.html
 
#  Курицын Никита 6232
# Task_1 Пайплайн, который обучает любой классификатор из sklearn по заданному набору параметров. 
    1. Был реализован пайпайн  wait_for_new_file >> extract_audio >> transform_audio_to_text >> summarize_text >> save_to_pdf.
    2. FileSensor(wait_for_new_file) сканировал целевую папку на наличие файл WC.mp4.
    3. После появления файла активировался DockerOperator(extract_audio) для извлечения аудио из видеофайла. Был создан docker образ с библиотекой ffmpeg.
    3. Далее другой DockerOperator(transform_audio_to_text) с помощью huggingface отрпавляет запросы для перевода речи в текст. Т.к. аудио было больше 30 сек. пришлось разбивать на короткие фрагменты и отправлять поочередено запросы. Был создан образ с библиотеками ffmpeg, requests, pydub.
    4. Далее DockerOperator делал коспект по полному тексту, также с помощью запросов в huggingfaceю
    5. Сохранение конспекта в ПДФ формат с помощью библиотеки FPDF.Был создан образ с библиотекой fpdf.
В качестве видео была выла выбрана речь Черчилля. Результаты работы перевода в текст находится в файле text.txt, конспект в summary.txt,  ПДФ файле - result.pdf.
![Пример изображения](https://github.com/BandooSs/Lab-2-2024/blob/main/1.PNG)
# Task_2 Пайплайн, который выбирает лучшую модель из обученных и производит её хостинг.
    1. Был реализован пайплайн wait_for_new_file >> read_data >> train_model.
    2. PythonSensor(wait_for_new_file) - кастомный сканер файлов, искал появление новой директории с именем data.
    3. DockerOperator(read_data) - считывание изображений и подготвка их к загрузке в модель (записывались в файлы с расширенем .npy).
    4. DockerOperator(train_model) - считывал подготовленный данные, настройки модели и запускал обучение модели на считанных данных. Также вел ЛОГ по каждой эпохе (log.txt).
